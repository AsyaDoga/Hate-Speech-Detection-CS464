{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce GTX 1060\n",
      "Memory Stats:\n",
      "  - Allocated: 0.0 GB\n",
      "  - Cached:    0.0 GB\n",
      "  - Total:     6.0 GB\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "from datasets import load_dataset\n",
    "from toxic_comment_collection import *\n",
    "\n",
    "#get_dataset('basile2019')\n",
    "# setting device as GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# CUDA device information\n",
    "if device.type == 'cuda':\n",
    "    print('GPU Name:', torch.cuda.get_device_name(0))\n",
    "    print('Memory Stats:')\n",
    "    print('  - Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('  - Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    print('  - Total:    ', round(torch.cuda.get_device_properties(0).total_memory/1024**3,1), 'GB')\n",
    "\n",
    "# for reproducable results\n",
    "torch.manual_seed(464)\n",
    "torch.cuda.manual_seed(464)\n",
    "np.random.seed(464)\n",
    "random.seed(464)\n",
    "if device.type == 'cuda':\n",
    "    torch.backends.cudnn.deterministic=True    \n",
    "get_dataset('basile2019')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "basile_ = pd.read_csv(\"./files/basile2019/basile2019en.csv\", sep=\"\\t\")#.to_numpy()\n",
    "gibert_ = pd.read_csv(\"./files/gibert2018/gibert2018en.csv\", sep=\"\\t\")#.to_numpy()\n",
    "chung_ = pd.read_csv(\"./files/chung2019/chung2019.csv\", sep=\"\\t\")#.to_numpy()\n",
    "#print(chung_[0,1])\n",
    "#print(gibert_[0,1])\n",
    "\n",
    "basile_['labels'] = basile_['labels'].astype('|S40')\n",
    "basile_['labels'].loc[basile_['labels'] == b'[]'] = 0\n",
    "basile_['labels'].loc[basile_['labels'] != b'[]'] = 1\n",
    "basile_data = basile_['text'].to_list()\n",
    "basile_labels = basile_['labels'].to_list()\n",
    "print(len(basile_data))\n",
    "print(len(basile_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10703\n",
      "5256\n"
     ]
    }
   ],
   "source": [
    "gibert_['labels'] = gibert_['labels'].astype('|S40')\n",
    "gibert_.drop(gibert_.index[gibert_['labels'] == b\"['idk/skip']\"], inplace=True)\n",
    "gibert_.drop(gibert_.index[gibert_['labels'] == b\"['relation']\"], inplace=True)\n",
    "gibert_['labels'].loc[gibert_['labels'] == b\"['none']\"] = 0\n",
    "gibert_['labels'].loc[gibert_['labels'] == b\"['hate']\"] = 1\n",
    "gibert_.head()\n",
    "gibert_data = gibert_['text'].to_list()\n",
    "gibert_labels = gibert_['labels'].to_list()\n",
    "print(len(gibert_labels))\n",
    "#print(len(gibert_labels[gibert_labels['labels'] == 1]))\n",
    "\n",
    "\n",
    "chung_['labels'] = chung_['labels'].astype('|S40')\n",
    "chung_['labels'].loc[chung_['labels'] == b\"['hate', 'Islamophobia']\"] = 1\n",
    "chung_data = chung_['text'].to_list()\n",
    "chung_labels = chung_['labels'].to_list()\n",
    "#print(chung_data[2])\n",
    "#print(len(chung_labels))\n",
    "\n",
    "qian_ = pd.read_csv(\"./files/qian2019/qian2019en_reddit.csv\", sep=\"\\t\")\n",
    "qian_['labels'] = qian_['labels'].astype('|S40')\n",
    "qian_.drop(qian_.index[qian_['labels'] == b'[]'], inplace=True)\n",
    "qian_['labels'].loc[qian_['labels'] == b\"['hate']\"] = 1\n",
    "qian_data = qian_['text'].to_list()\n",
    "qian_labels = qian_['labels'].to_list()\n",
    "print(len(qian_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26815\n",
      "26815\n"
     ]
    }
   ],
   "source": [
    "res_data = basile_data + chung_data + gibert_data + qian_data\n",
    "print(len(res_data))\n",
    "res_labels = basile_labels + chung_labels + gibert_labels + qian_labels\n",
    "print(len(res_labels))\n",
    "\n",
    "import pickle\n",
    "with open(\"hate_dataset\", \"wb\") as fp:   #Pickling\n",
    "   pickle.dump(res_data, fp)\n",
    " \n",
    "with open(\"hate_labels\", \"wb\") as fp:   \n",
    "    pickle.dump(res_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "with open(\"dataset/hate_dataset\") as fp:\n",
    "    a = pickle.load(fp)\n",
    "print(len(a))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8a8c919bd6732bc823198b1f46ac0e8ccd3587ce249f818d866e9fc28155d7a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
